{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def get_recent_file(bucket_name):\n",
    "    s3 = boto3.client('s3')\n",
    "    arquivos = s3.list_objects_v2(Bucket=bucket_name)['Contents']\n",
    "    \n",
    "    return max(arquivos, key=lambda x: x['LastModified'])['Key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_filie = get_recent_file('stagged-sprint-3') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('raw_stage')\\\n",
    "        .config(\"spark.sql.files.ignoreCorruptFiles\", \"true\")\\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(f's3a://stagged-sprint-3/{last_filie}', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_npk = df.select(df.n,df.p,df.k,df.date)\n",
    "df_npk = df_npk.withColumnRenamed('n','nitrogen')\n",
    "df_npk = df_npk.withColumnRenamed('p','phosphorus')\n",
    "df_npk = df_npk.withColumnRenamed('k','potassium')\n",
    "df_npk.write.csv(f\"consumed/npk/{last_filie}.csv\", header=True, mode=\"overwrite\")\n",
    "df_npk.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmp = df.select(df.temp,df.press,df.date)\n",
    "df_bmp = df_bmp.withColumnRenamed('temp','temperature')\n",
    "df_bmp = df_bmp.withColumnRenamed('press','pressure')\n",
    "df_bmp.write.csv(f\"consumed/bmp/{last_filie}.csv\", header=True, mode=\"overwrite\")\n",
    "df_bmp.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anemometro = df.select(df.var,df.date)\n",
    "df_anemometro = df_anemometro.withColumnRenamed('var', 'air_speed')\n",
    "df_anemometro.write.csv(f\"consumed/anemometro/{last_filie}.csv\", header=True, mode=\"overwrite\")\n",
    "df_anemometro.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dht = df.select(df.temp,df.humi,df.date)\n",
    "df_dht = df_dht.withColumnRenamed('temp','temperature')\n",
    "df_dht = df_dht.withColumnRenamed('humi','humidity')\n",
    "df_dht.write.csv(f\"consumed/dht/{last_filie}.csv\", header=True, mode=\"overwrite\")\n",
    "df_dht.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tcrt = df.select(df.caps,df.qtdg)\n",
    "df_tcrt = df_tcrt.withColumnRenamed('caps','capacity')\n",
    "df_tcrt = df_tcrt.withColumnRenamed('qtdg','collected')\n",
    "df_tcrt.write.csv(f\"consumed/tcrt/{last_filie}.csv\", header=True, mode=\"overwrite\")\n",
    "df_tcrt.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_umigrain = df.select(df.umig,df.date)\n",
    "df_umigrain = df_umigrain.withColumnRenamed('umig','humidity_grain')\n",
    "df_umigrain.write.csv(f\"consumed/umigrain/{last_filie}.csv\", header=True, mode=\"overwrite\")\n",
    "df_umigrain.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
